<!DOCTYPE html>
<html lang="en">

<head>
    <meta charset="UTF-8">
    <meta content="IE=edge" http-equiv="X-UA-Compatible">
    <meta content="width=device-width,initial-scale=1" name="viewport">
    <meta content="description" name="description">
    <meta name="google" content="notranslate"/>
    <meta content="Mashup templates have been developped by Orson.io team" name="author">

    <!-- Disable tap highlight on IE -->
    <meta name="msapplication-tap-highlight" content="no">

    <link rel="robot-icon" sizes="180x180" href="./assets/robot-icon-180x180.png">
    <link href="./assets/robot-icon-180x180.ico" rel="icon">

    <title>Tech Watch</title>

    <link href="./main.3f6952e4.css" rel="stylesheet">
</head>

<body class="">
<div id="site-border-left"></div>
<div id="site-border-right"></div>
<div id="site-border-top"></div>
<div id="site-border-bottom"></div>
<!-- Add your content of header -->
<header>
    <nav class="navbar  navbar-fixed-top navbar-default">
        <div class="container">
            <button type="button" class="navbar-toggle collapsed" data-toggle="collapse" data-target="#navbar-collapse"
                    aria-expanded="false">
                <span class="sr-only">Toggle navigation</span>
                <span class="icon-bar"></span>
                <span class="icon-bar"></span>
                <span class="icon-bar"></span>
            </button>

            <div class="collapse navbar-collapse" id="navbar-collapse">
                <ul class="nav navbar-nav ">
                    <li><a href="./index.html" title="">Home</a></li>
                    <li><a href="./intro.html" title="">Introduction</a></li>
                    <li><a href="./article1.html" title="">GANs</a></li>
                    <li><a href="./article2.html" title="">Beautiful Art vs Terrifying Deepfakes</a></li>
                    <li><a href="./article3.html" title="">What's next ?</a></li>
                    <li><a href="./news.html" title="">News</a></li>
                    <li><a href="./videos.html" title="">Videos</a></li>
                    <li><a href="./about.html" title="">About</a></li>
                </ul>

            </div>
        </div>
    </nav>
</header>
<div class="section-container">
    <div class="container">
        <div class="row">
            <div class="col-xs-12">
                <img src="./assets/images/work001-01.jpg" class="img-responsive" alt="">
                <div class="card-container">
                    <div class="text-center">
                        <h1 class="h2">Generative Adversarial Networks</h1>
                    </div>
                    <p style="text-align:center; font-size:120%;">Cet article présente les grands principes liés aux
                        réseaux antagonistes génératifs</p>

                    <blockquote>
                        <p>“What I Cannot Create, I Do Not Understand”</p>
                        <small class="pull-right">Richard Feynman</small>
                    </blockquote>
                </div>
            </div>


            <div class="col-md-8 col-md-offset-2 section-container-spacer">
                <div class="row">
                    <div class="col-xs-12 col-md-6">
                        <img src="./assets/images/work001-02.jpg" class="img-responsive" alt="">
                        <p>Saliency Map : compréhension d'un concept</p>
                    </div>
                    <div class="col-xs-12 col-md-6">
                        <img src="./assets/images/work001-03.jpg" class="img-responsive" alt="">
                        <p>Une IA forte est-elle possible ?</p>
                    </div>
                </div>
            </div>

            <div class="col-xs-12">

                <p style="text-align:justify; font-size:160%; font-weight:400;">&emsp;
                    Les GANs, generative adversarial networks ou réseaux antagonistes génératifs, sont une classe de
                    réseaux de neurones
                    qui ont gagné en popularité au cours des deux dernières années, et pour de bonnes raisons. En termes
                    simples, ils
                    permettent à un réseau d'apprendre à générer des données fidèles à des données types. Cela signifie
                    que les
                    GANs doivent avoir une bonne compréhension des données ingérées (ou plus précisément de la
                    distribution de ces données).
                    La citation de Richard Feynman résonne bien avec cela.
                </p>

                <div style="height:20px;font-size:20px;">&nbsp;</div>

                <p style="text-align:justify; font-size:160%; font-weight:400;">&emsp;
                    Le terme "génératif" évoque l'objectif global du modèle : créer de nouvelles données. Les données
                    qu'un GAN apprendra
                    à générer dépendant du choix de l'ensemble d’entraînement - par exemple, si nous voulons qu'un GAN
                    peigne comme Leonardo
                    da Vinci, nous utiliserons un ensemble de données d’entraînement composé d'œuvres du peintre.
                </p>

                <div style="height:20px;font-size:20px;">&nbsp;</div>

                <p style="text-align:justify; font-size:160%; font-weight:400;">&emsp;
                    Le terme "antagoniste" désigne la dynamique concurrentielle entre les deux algorithmes qui
                    constituent le cadre du GAN :
                    le générateur et le discriminateur. L'objectif du générateur est de créer des exemples qui ne se
                    distinguent pas des
                    données réelles dans le jeu d'entraînement. Dans notre exemple, cela signifie produire des tableaux
                    qui ressemblent à
                    ceux de Léonard de Vinci. L'objectif du discriminateur est de distinguer les faux exemples produits
                    par le générateur
                    des exemples réels provenant de l'ensemble de données d’entraînement. Dans notre exemple, le
                    discriminateur joue le rôle
                    d'un expert en art qui évalue l'authenticité des peintures que l'on croit être celles de Léonard da
                    Vinci. Les deux réseaux
                    essaient constamment de se déjouer l'un l'autre : plus le générateur parvient à créer des données
                    convaincantes,
                    plus le discriminateur doit être en mesure de distinguer les exemples réels des faux.
                </p>

                <div style="height:20px;font-size:20px;">&nbsp;</div>

                <p style="text-align:justify; font-size:160%; font-weight:400;">&emsp;
                    Enfin, le mot "réseaux" désigne la classe de modèles d'apprentissage automatique la plus couramment
                    utilisée pour
                    représenter le générateur et le discriminateur : les réseaux de neurones. Comme leur nom l'indique,
                    ces modèles
                    s'inspirent du cerveau humain - ils utilisent un ensemble de nœuds interconnectés, ou "neurones",
                    pour traiter
                    leurs calculs.
                </p>

                <div style="height:20px;font-size:20px;">&nbsp;</div>
                <p align="center">
                    <img src="./assets/images/gan-metaphore.jpg" class="img-responsive" alt="" align="middle">
                </p>
                <p></p>
                <div style="height:30px;font-size:20px;">&nbsp;</div>

                <p style="text-align:justify; font-size:160%; font-weight:400;">&emsp;
                    Bien que les mathématiques qui sous-tendent les GAN soient assez complexes, il existe de nombreuses
                    analogies avec
                    le monde réel qui peuvent rendre l'intuition qui les sous-tend plus facile à comprendre. Nous
                    pouvons prendre l'exemple
                    d'un faussaire d'art (le "générateur") qui essaie de tromper un expert en art (le "discriminateur").
                    Plus les fausses
                    peintures fabriquées par le faussaire sont convaincantes, plus l'expert en art doit être en mesure
                    d'en déterminer
                    l'authenticité. C'est également vrai dans le cas contraire : plus l'expert en art est en mesure de
                    dire si un tableau
                    particulier est authentique, plus le faussaire doit améliorer son art pour éviter d'être pris en
                    flagrant délit.
                    Une autre métaphore souvent utilisée pour décrire les GAN - une métaphore que Ian Goodfellow
                    lui-même aime utiliser -
                    est celle d'un criminel (le "générateur") qui contrefait de l'argent et d'un détective (le
                    "discriminateur") qui tente
                    de l'attraper. Plus les faux billets ont l'air authentiques, plus la police doit être en mesure de
                    les détecter, et
                    vice versa.
                </p>

                <div style="height:20px;font-size:20px;">&nbsp;</div>

                <p style="text-align:justify; font-size:160%; font-weight:400;">&emsp;
                    L'une des applications les plus courantes des GAN est la génération d'images. Si on dispose d’une
                    certaine quantité d’images
                    représentant des visages, un GAN peut donc apprendre à générer des images de visages réalistes sans
                    jamais répliquer aucune
                    des images individuellement. En réalité, avec un nombre assez conséquent d’images, le réseau apprend
                    la représentation du
                    concept de visage humain à partir des simples échantillons et est en mesure de générer des images
                    qui respecte ce standard.
                    De plus, cela est fait sans qu’à aucun moment le générateur n'ait un accès direct aux images du jeu
                    d’entraînement.

                    En effet, à la suite du travail du discriminateur, deux boucles de feedbacks transmettent aux deux
                    réseaux de neurones
                    l’identité des designs sur lesquels ils doivent s’améliorer. Le générateur reçoit l’identité des
                    designs sur lesquels il a
                    été démasqué par le discriminateur, le discriminateur reçoit l’identité des designs sur lesquels il
                    a été trompé par le
                    générateur. Les deux algorithmes entretiennent donc une relation gagnant-gagnant d’amélioration
                    continue : le générateur
                    apprend à créer des designs de plus en plus réalistes et le discriminateur apprend à identifier de
                    mieux en mieux les
                    designs réels de ceux provenant du générateur.
                </p>

                <div style="height:30px;font-size:20px;">&nbsp;</div>
                <p align="center">
                    <img src="./assets/images/gan-principe.jpg" class="img-responsive" alt="" align="middle">
                </p>
                <p></p>
                <div style="height:30px;font-size:20px;">&nbsp;</div>

                <p style="text-align:justify; font-size:160%; font-weight:400;">&emsp;
                    A titre d’exemple, ci-dessous, les dernières images de visages hyperréalistes générées par NVIDIA en
                    2018 ainsi que les
                    images réelles utilisée lors de l’apprentissage. Les résultats sont impressionants et à première vue
                    la difficulté pour démêler le
                    vrai du faux est conséquente. Le site <a href="http://www.whichfaceisreal.com">Which Face Is
                        Real</a> a pour objectif de
                    « faire prendre conscience aux gens de la facilité avec laquelle les identités numériques peuvent
                    être falsifiées et de les
                    aider à repérer ces contrefaçons d'un seul coup d'œil ». En plus de proposer une page ludique qui
                    après chaque clic propose
                    à l’utilisateur de distinguer la personne réelle de celle générée, le site liste entre autres
                    différentes astuces afin de
                    démêler le vrai du faux et « voir à travers les illusions d'un monde fabriqué ».
                </p>

                <div style="height:20px;font-size:20px;">&nbsp;</div>
                <p align="center">
                    <img src="./assets/images/fakevsreal.jpg" class="img-responsive" alt="" align="middle">
                </p>
                <p></p>
                <div style="height:30px;font-size:20px;">&nbsp;</div>

                <p style="text-align:justify; font-size:160%; font-weight:400;">&emsp;
                    Quelques astuces : regardez de plus près l'arrière plan des images, le contour du visage près des
                    oreilles et parfois
                    les dents où les yeux. Ce sont en effet les composantes les plus difficiles à représenter par le
                    générateur.
                </p>

                <div style="height:30px;font-size:20px;"></div>

                <p style="text-align:justify; font-size:170%; font-weight:400;">
                    <b>En quoi les GANs représentent une avancée importante pour le deep learning ?</b>
                </p>

                <div style="height:20px;font-size:20px;"></div>

                <p style="text-align:justify; font-size:160%; font-weight:400;">&emsp;
                    L’entraînement de réseaux de neurones profonds exige une abondance de données, et les succès les
                    plus notables ont été
                    obtenus lorsque cette condition était remplie. L'apprentissage supervisé, où il existe de grands
                    ensembles de données
                    étiquetés, comme <a href="http://www.image-net.org/">ImageNet</a>, est un exemple de réussite
                    majeure. Cependant obtenir de telles données labellisées est coûteux
                    et demande une force de travail conséquente.
                </p>

                <div style="height:20px;font-size:20px;">&nbsp;</div>
                <p align="center">
                    <img src="./assets/images/clic-slave.gif" class="img-responsive" alt="" align="middle">
                </p>
                <p></p>
                <div style="height:30px;font-size:20px;">&nbsp;</div>

                <p style="text-align:justify; font-size:160%; font-weight:400;">&emsp;
                    Les réseaux antagonistes, cependant, partent d'une perspective différente.
                    Les données précieuses sont les données dont les deux réseaux tirent des leçons, c'est-à-dire les
                    données fournies par le
                    réseau générateur. <b>L'ensemble de données réelles auquel le discriminateur a accès peut rester
                        relativement petit par rapport
                        à d'autres méthodes</b> : 70 000 images pour la génération de visage de NVIDIA contre 1 000 000
                    d’images pour entraîner des
                    modèles comme <a href="https://medium.com/@smallfishbigsea/a-walk-through-of-alexnet-6cbd137a5637">AlexNet</a>
                    ou
                    <a href="https://towardsdatascience.com/an-overview-of-resnet-and-its-variants-5281e2f56035">ResNet</a>.
                </p>

                <div style="height:20px;font-size:20px;">&nbsp;</div>
                <p align="center">
                    <img src="./assets/images/dataset-deeplearning.jpg" class="img-responsive" alt="" align="middle">
                </p>
                <p></p>
                <div style="height:30px;font-size:20px;">&nbsp;</div>

                <p style="text-align:justify; font-size:160%; font-weight:400;">&emsp;
                    En 2014, Christian Szegedy et quelques autres chercheurs chez Google, ont fait remarquer à travers
                    un
                    <a href="https://arxiv.org/abs/1312.6199">article scientifique</a> que les réseaux de neurones
                    pouvaient
                    être trompés facilement en ajoutant simplement une petite quantité de bruit à une image. Par exemple
                    en ajoutant un léger
                    bruit imperceptible à l’œil nu à une image appartenant à la classe « bus » ce dernier pourra être
                    perçu par le réseau de
                    neurones comme appartenant à la classe « autruche » et ce avec une confiance bien meilleure que
                    lorsqu’il prédisait la classe
                    correcte. Mathématiquement, ce changement de classe peut être implémenté en utilisant la méthode du
                    Fast Gradient Sign Method
                    (FGSM ajoute simplement de façon itérative une petite quantité de bruit dans la direction du
                    gradient de la fonction
                    objectif – ici la fausse classe désirée - par rapport aux valeurs d'entrée). <b>L'une des solutions
                        proposées pour corriger ces
                        réseaux de neurones profonds est d’entraîner le réseau sur des « adversarial examples » ou
                        exemples contradictoires</b>. Ces
                    derniers peuvent être générés à l'aide de modèles génératifs dont les plus notables sont les
                    PixelCNN, les Variational
                    Auto-Encoders et bien évidemment les Generative Adversarial Networks.
                </p>

                <div style="height:20px;font-size:20px;">&nbsp;</div>
                <p align="center">
                    <img src="./assets/images/nets-fool.jpg" class="img-responsive" alt="" align="middle">
                </p>
                <p></p>
                <div style="height:30px;font-size:20px;">&nbsp;</div>

                <p style="text-align:justify; font-size:170%; font-weight:400;">
                    <b>Les limites des GANs et les champs de recherche possibles</b>
                </p>

                <div style="height:20px;font-size:20px;"></div>

                <p style="text-align:justify; font-size:160%; font-weight:400;">&emsp;
                    Les GANs sont basés sur ce qu’on appelle un « zero-sum non-cooperative game ». En bref, si l'un
                    gagne
                    (générateur ou discriminateur), l'autre perd. Un jeu à somme nulle est aussi appelé minimax. Votre
                    adversaire veut
                    maximiser ses actions et vos actions cherchent à minimiser les actions de l’adversaire. En théorie
                    des jeux, le modèle
                    GAN converge lorsque le discriminateur et le générateur atteignent un équilibre de Nash. C'est le
                    point optimal pour
                    l'équation minimax ci-dessous.
                </p>

                <div style="height:20px;font-size:20px;">&nbsp;</div>
                <p align="center">
                    <img src="./assets/images/gan-formula.jpg" class="img-responsive" alt="" align="middle">
                </p>
                <p></p>
                <div style="height:30px;font-size:20px;">&nbsp;</div>

                <p style="text-align:justify; font-size:160%; font-weight:400;">&emsp;
                    Cependant pour que la convergence globale su système arrive à son terme, il faut que chaque réseau
                    progresse globalement
                    au même rythme de convergence lors de la phase d’entraînement. <b>Si, toutefois, l’un des deux
                        réseaux converge plus rapidement,
                        il devient alors trop fort et prend le pas sur l’autre empêchant la convergence globale du
                        système</b>.
                </p>

                <div style="height:20px;font-size:20px;"></div>

                <p style="text-align:justify; font-size:160%; font-weight:400;">&emsp;
                    Une des conséquences de la nécessité d’une convergence homogène et simultanée des réseaux est la <b>difficulté
                        de travailler
                        avec des données complexes, en particulier de haute résolution dans le cas des images</b>. Plus
                    le nombre de pixels au sein d’une
                    image est élevé plus les détails seront fournis et la convergence lente pour le générateur alors que
                    le discriminateur pourra
                    lui effectuer sa tâche plus facilement. Néanmoins, aux cours des dernières années, des solutions ont
                    été apportées à ce problème
                    en n’augmentant que progressivement la résolution des images. Ainsi on se préoccupe d’abord des
                    traits globaux du design pour
                    ensuite se concentrer sur les détails locaux.
                </p>

                <div style="height:20px;font-size:20px;"></div>

                <p style="text-align:justify; font-size:160%; font-weight:400;">&emsp;
                    L’utilité de la génération de nouvelles données réside dans la variabilité de ces données. Néanmoins
                    l’objectif du générateur
                    n’est pas de créer de la nouveauté en termes de diversité mais seulement de tromper le
                    discriminateur. Ainsi, bien que le
                    générateur ne puisse pas fournir de copie d’une donnée existante car il n’y a tout simplement pas
                    accès, <b>la diversité n’est
                        pas toujours garantie : c'est le mode collapse</b>. Si les images générées sont bien « nouvelles
                    » au sens premier du terme (aucune ne sont exactement
                    similaires), il se peut que le générateur prenne peu en compte l’impulsion aléatoire initiale et
                    génère ainsi fréquemment des
                    images très similaires entre elles. La raison à cela est qu’une image générée qui trompera
                    facilement le discriminateur aura
                    tendance à être régénérée, non pas à l’identique, mais de façon très proche. On obtiendra alors un
                    réseau qui génère des
                    images très semblables : c’est que qu’on appelle le mode collapse. Ce phénomène est particulièrement
                    observé lorsque la
                    diversité intrinsèque des données générées est moins élevée. Par exemple, si l’on cherche à générer
                    une fleur aux pétales
                    blancs et au pistil jaune, la diversité des images créées sera moindre que pour un oiseau orangé.
                    Une raison à cela est
                    qu’un oiseau peut se mouvoir librement dans son environnement - il en découle une diversité plus
                    grande au sein de la base
                    d’entraînement.
                </p>

                <div style="height:20px;font-size:20px;">&nbsp;</div>
                <p align="center">
                    <img src="./assets/images/mode-collapse.jpg" class="img-responsive" alt="" align="middle">
                </p>
                <p></p>
                <div style="height:30px;font-size:20px;">&nbsp;</div>

            </div>
        </div>
    </div>


    <footer class="footer-container text-center">
        <div class="container">
            <div class="row">
                <div class="col-xs-12">
                    <p></p>
                </div>
            </div>
        </div>
    </footer>

    <script>
        document.addEventListener("DOMContentLoaded", function (event) {
            navActivePage();
        });
    </script>

    <!-- Google Analytics: change UA-XXXXX-X to be your site's ID

    <script>
      (function (i, s, o, g, r, a, m) {
        i['GoogleAnalyticsObject'] = r; i[r] = i[r] || function () {
          (i[r].q = i[r].q || []).push(arguments)
        }, i[r].l = 1 * new Date(); a = s.createElement(o),
          m = s.getElementsByTagName(o)[0]; a.async = 1; a.src = g; m.parentNode.insertBefore(a, m)
      })(window, document, 'script', '//www.google-analytics.com/analytics.js', 'ga');
      ga('create', 'UA-XXXXX-X', 'auto');
      ga('send', 'pageview');
    </script>

    -->
    <script type="text/javascript" src="./main.70a66962.js"></script>
</body>

</html>